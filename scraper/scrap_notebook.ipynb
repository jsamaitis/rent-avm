{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This notebook is now primarily used as a scrap notebook for quick code-testing purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format verifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/raw_listings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#historical_dataset_info.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import logging\n",
    "\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NpEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.integer):\n",
    "            return int(obj)\n",
    "        elif isinstance(obj, np.floating):\n",
    "            return float(obj)\n",
    "        elif isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        else:\n",
    "            return super(NpEncoder, self).default(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-203-597592b72a04>:1: RuntimeWarning: invalid value encountered in sqrt\n",
      "  np.sqrt(-1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-26 15:31:57,977 [INFO] Found all of the expected Variables.\n",
      "2020-05-26 15:31:57,979 [INFO] Found no new Variables\n",
      "2020-05-26 15:31:57,980 [INFO] Found no new Values.\n",
      "2020-05-26 15:31:57,985 [INFO] Found no new \"ojbect\" type variables.\n",
      "2020-05-26 15:31:58,317 [INFO] Saved new statistics for Variables: []\n",
      "2020-05-26 15:31:58,368 [INFO] Updated statistics for all existing Variables.\n",
      "2020-05-26 15:31:58,369 [INFO] All variables passed the statistical tests succesfully with a p-value of 0.05.\n",
      "2020-05-26 15:31:58,370 [INFO] All variables passed the missing value check with missing value percentage deviation of 0.1.\n",
      "2020-05-26 15:31:58,383 [INFO] Succesfully updated historical_dataset_info.json file.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class FormatVerifier:\n",
    "    def __init__(self, p_value=0.05, missing_value_deviation=0.1):\n",
    "        \"\"\"\n",
    "        TODO: Descr.\n",
    "        \"\"\"\n",
    "        self.p_value = p_value\n",
    "        self.missing_deviation = missing_value_deviation\n",
    "        \n",
    "        # Setup Logging.\n",
    "        logging.basicConfig(\n",
    "            level=logging.INFO,\n",
    "            format=\"%(asctime)s [%(levelname)s] %(message)s\",\n",
    "            handlers=[\n",
    "                logging.FileHandler(\"format_verifier.log\", encoding='utf-8'),\n",
    "                logging.StreamHandler()\n",
    "            ]\n",
    "        )\n",
    "        # Load config file.\n",
    "        with open('config_verifier.json', 'r', encoding='utf-8') as f:\n",
    "                self.config = json.load(f)\n",
    "        \n",
    "        # Load, if historical_dataset_info file exists.\n",
    "        if os.path.exists('historical_dataset_info.json'):\n",
    "            with open('historical_dataset_info.json', 'r', encoding='utf-8') as f:\n",
    "                self.historical_info = json.load(f)\n",
    "        else:\n",
    "            self.historical_info = {\n",
    "                'names': {\n",
    "                    'variable_names': [],\n",
    "                    'value_names': []\n",
    "                },\n",
    "                'statistics': {}\n",
    "            }\n",
    "            \n",
    "        pass\n",
    "            \n",
    "    def t_test(self, x_stats, y_stats):\n",
    "        \"\"\"\n",
    "        Customized t-test.\n",
    "\n",
    "        Sources: \n",
    "            [1] https://www.medcalc.org/calc/comparison_of_means.php\n",
    "            [2] https://towardsdatascience.com/inferential-statistics-series-t-test-using-numpy-2718f8f9bf2f\n",
    "        \"\"\"\n",
    "        # Get the pooled standard deviation.\n",
    "        s = np.sqrt(\n",
    "            ((x_stats['samples'] - 1)*x_stats['std']**2 + (y_stats['samples'] - 1)*y_stats['std']**2)  / (x_stats['samples'] + y_stats['samples'] - 2)\n",
    "        )\n",
    "\n",
    "        # Get the t-statistic. + 0.0001 is to avoid dividing by 0.\n",
    "        t = (x_stats['mean'] - y_stats['mean'])/(s*np.sqrt(2/(x_stats['samples'] + y_stats['samples'])) + 0.0001)\n",
    "\n",
    "        # Get the degrees-of-freedom.\n",
    "        df = 2*(x_stats['samples'] + y_stats['samples']) - 2\n",
    "\n",
    "        # Get the p-value.\n",
    "        p = 1 - stats.t.cdf(t,df=df)\n",
    "\n",
    "        return p\n",
    "        \n",
    "    def check_names(self, df):\n",
    "        \"\"\"\n",
    "        Checks for any old and any new formats.\n",
    "        \"\"\"\n",
    "        column_names = df.columns.values\n",
    "\n",
    "        # Split pseudo-categorical variables to get their Variable and Value information.\n",
    "        column_names_split = [name.split('_') for name in column_names]\n",
    "        variable_names = [name[0] for name in column_names_split if len(name) == 1]\n",
    "        value_names = [name[1] for name in column_names_split if len(name) == 2]\n",
    "\n",
    "        # Check and report if all of the old variables are present. \n",
    "        # Values are not checked because they can vary day-to-day.\n",
    "        variable_names_not_found = [name for name in self.historical_info['names']['variable_names'] if name not in variable_names]\n",
    "        \n",
    "        if len(variable_names_not_found) > 0:\n",
    "            logging.warning('Variables expected, but not found in the dataset: {}'.format(variable_names_not_found))\n",
    "        else:\n",
    "            logging.info('Found all of the expected Variables.')\n",
    "        \n",
    "        variable_names_new = [name for name in variable_names if name not in self.historical_info['names']['variable_names']]\n",
    "        value_names_new = [name for name in variable_names if name not in self.historical_info['names']['value_names']]\n",
    "        \n",
    "        # Report any new Variable/Value names if any were found.\n",
    "        if len(variable_names_new) > 0:\n",
    "            logging.warning('Found previously unseen Variables: {}'.format(variable_names_new))\n",
    "            self.historical_info['names']['variable_names'].extend(variable_names_new)\n",
    "        else:\n",
    "            logging.info('Found no new Variables')\n",
    "        \n",
    "        if len(value_names_new) > 0:\n",
    "            logging.warning('Found previously unseen value names: {}'.format(value_names_new))\n",
    "            self.historical_info['names']['value_names'].extend(value_names_new)\n",
    "        else:\n",
    "            logging.info('Found no new Values.')\n",
    "        \n",
    "        pass\n",
    "    \n",
    "    def check_types(self, df):\n",
    "        \"\"\"\n",
    "        Checks if all the data types match up. Everything should be numeric except strings in config.\n",
    "        \"\"\"\n",
    "        \n",
    "        names_strings = df.select_dtypes('object').columns.values\n",
    "        names_strings_unexpected = [name for name in names_strings if name not in self.config['types']['string']]\n",
    "        \n",
    "        if len(names_strings_unexpected) > 0:\n",
    "            logging.warning('Found variables are not expected to be \"object\" type: {}.'.format(names_strings_unexpected))\n",
    "        else:\n",
    "            logging.info('Found no new \"ojbect\" type variables.')\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    def check_statistics(self, df):\n",
    "        \"\"\"\n",
    "        Checks for statistical differences between historical_statistics and current batch.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Get current batch statistics, add missing value percentage as well as number of samples.\n",
    "        statistics = df.select_dtypes(exclude='object').describe().T\n",
    "        statistics = statistics[['mean', 'std', 'min', 'max']]\n",
    "        statistics['missing'] = df.isna().mean()\n",
    "        statistics['samples'] = df.count()\n",
    "        statistics['samples_total'] = df.shape[0]\n",
    "        statistics['sum'] = df.sum()\n",
    "        statistics['sum_squares'] = (df.select_dtypes(exclude='object') ** 2).sum()\n",
    "        \n",
    "        # Split variables into ones with historical statistical data and ones without.\n",
    "        variables_existing = [name for name in statistics.index.values if name in self.historical_info['statistics'].keys()]\n",
    "        variables_new = [name for name in statistics.index.values if name not in self.historical_info['statistics'].keys()]\n",
    "        \n",
    "        # Save new variable statistics and report. \n",
    "        for variable in variables_new:\n",
    "            self.historical_info['statistics'][variable] = statistics.loc[variable].to_dict()\n",
    "        \n",
    "        logging.info('Saved new statistics for Variables: {}'.format(variables_new))\n",
    "\n",
    "            \n",
    "        # Statistical tests.\n",
    "        variables_failed_test = []\n",
    "        variables_failed_missing = []\n",
    "        for variable in variables_existing:\n",
    "            \n",
    "            # Perform a t-test, add to variables_failed if it failed the test.\n",
    "            p_value = self.t_test(self.historical_info['statistics'][variable], statistics.loc[variable].to_dict())\n",
    "            if p_value <= self.p_value:\n",
    "                variables_failed_test.append(variable)\n",
    "                \n",
    "            # Compare missing values with self.missing_deviation to see if it's more than expected.\n",
    "            missing_difference =abs(self.historical_info['statistics'][variable]['missing'] - statistics.loc[variable, 'missing'])\n",
    "            if missing_difference >= self.missing_deviation:\n",
    "                variables_failed_missing.append(variable)\n",
    "                \n",
    "                \n",
    "            # Update the historical info of existing variables.\n",
    "            # Mean, sample sizes.\n",
    "            samples_total_new = self.historical_info['statistics'][variable]['samples_total'] + statistics.loc[variable, 'samples_total']\n",
    "            samples_new = self.historical_info['statistics'][variable]['samples'] + statistics.loc[variable, 'samples']\n",
    "            mean_new = (self.historical_info['statistics'][variable]['mean'] + statistics.loc[variable, 'mean']) / samples_new\n",
    "            \n",
    "            # Update the standard deviation. Source: https://stackoverflow.com/questions/1174984/how-to-efficiently-calculate-a-running-standard-deviation\n",
    "            sum_total = statistics.loc[variable, 'sum'] + self.historical_info['statistics'][variable]['sum']\n",
    "            sum_total_squares = statistics.loc[variable, 'sum_squares']  + self.historical_info['statistics'][variable]['sum_squares']\n",
    "            n_samples = statistics.loc[variable, 'samples'] + statistics.loc[variable, 'samples']\n",
    "            \n",
    "            # Get standard error if sigma is > 0, otherwise set it to nan.\n",
    "            sigma = (sum_total_squares / n_samples) - (sum_total / n_samples) ** 2\n",
    "            std_new = np.sqrt(sigma) if sigma >= 0 else np.nan\n",
    "            \n",
    "            # Update min and max values.\n",
    "            if statistics.loc[variable, 'min'] < self.historical_info['statistics'][variable]['min']:\n",
    "                min_new = statistics.loc[variable, 'min']\n",
    "            else:\n",
    "                min_new = self.historical_info['statistics'][variable]['min']\n",
    "                \n",
    "            if statistics.loc[variable, 'max'] > self.historical_info['statistics'][variable]['max']:\n",
    "                max_new = statistics.loc[variable, 'max']\n",
    "            else:\n",
    "                max_new = self.historical_info['statistics'][variable]['max']\n",
    "            \n",
    "            # Update the missing value percentage.\n",
    "            missing_weight_old = self.historical_info['statistics'][variable]['samples_total'] / (self.historical_info['statistics'][variable]['samples_total'] + statistics.loc[variable, 'samples_total'])\n",
    "            missing_weight_new = statistics.loc[variable, 'samples_total'] / (self.historical_info['statistics'][variable]['samples_total'] + statistics.loc[variable, 'samples_total'])\n",
    "            \n",
    "            missing_new = self.historical_info['statistics'][variable]['missing'] * missing_weight_old + statistics.loc[variable, 'missing'] * missing_weight_new\n",
    "            \n",
    "            \n",
    "            # Set the updated values to historical_info.\n",
    "            self.historical_info['statistics'][variable] = {\n",
    "                'std': std_new,\n",
    "                'mean': mean_new,\n",
    "                'min': min_new,\n",
    "                'max': max_new,\n",
    "                'missing': missing_new,\n",
    "                'samples': samples_new,\n",
    "                'samples_total': samples_total_new,\n",
    "                'sum': sum_total,\n",
    "                'sum_squares': sum_total_squares\n",
    "            }\n",
    "            \n",
    "        \n",
    "        # Log the results.\n",
    "        logging.info('Updated statistics for all existing Variables.')\n",
    "        \n",
    "        if len(variables_failed_test) > 0:\n",
    "            logging.warning('Found Variables that have failed the statistical test with p-value of {0}: {1}.'.format(self.p_value, variables_failed_test))\n",
    "        else:\n",
    "            logging.info('All variables passed the statistical tests succesfully with a p-value of {0}.'.format(self.p_value))\n",
    "               \n",
    "        if len(variables_failed_missing) > 0:\n",
    "            logging.warning('Found Variables that have failed the missing value check with missing value percentage deviation of {0}: {1}.'.format(self.missing_deviation, variables_failed_missing))\n",
    "        else:\n",
    "            logging.info('All variables passed the missing value check with missing value percentage deviation of {0}.'.format(self.missing_deviation))\n",
    "            \n",
    "        \n",
    "        # Saving the updated historical info into a file.\n",
    "        with open('historical_dataset_info.json', 'w') as f:\n",
    "            json.dump(self.historical_info, f, cls=NpEncoder)\n",
    "        \n",
    "        logging.info('Succesfully updated historical_dataset_info.json file.')\n",
    "        pass\n",
    "    \n",
    "    def verify(self, df):\n",
    "        \"\"\"\n",
    "        Final function combining all of the merging.\n",
    "        \"\"\"\n",
    "        \n",
    "        logging.info('Executing data checks.')\n",
    "        self.check_names(df)\n",
    "        self.check_types(df)\n",
    "        self.check_statistics(df)\n",
    "        logging.info('Succesfully executed all the data checks.')\n",
    "        \n",
    "        pass\n",
    "        \n",
    "\n",
    "format_verifier = FormatVerifier()\n",
    "format_verifier.f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20833333333333334"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_old = 2\n",
    "total_old = 4\n",
    "\n",
    "missing_new = 3\n",
    "total_new = 20\n",
    "\n",
    "missing_p_old = missing_old / total_old\n",
    "missing_p_new = (missing_new + missing_old) / (total_new + total_old)\n",
    "\n",
    "missing_p_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_p_old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20833333333333331"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_p_old*(total_old / (total_old + total_new)) + (missing_new / total_new) * (total_new / (total_old + total_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "    \"types\": {\n",
    "        \"string\": [\"ObjectDescription\", \"ListingUrl\", \"RealtorName\", \"RealtorOrganization\",\n",
    "                   \"BuildingEnergyClass\", \"BuildingEnergyClassCategory\", \"BuildingCity\",\n",
    "                   \"BuildingNeighbourhood\", \"BuildingStreet\", \"PastatoTipas\", \"Šildymas\", \n",
    "                   \"Įrengimas\", \"NamoNumeris\", \"ButoNumeris\", \"VidutiniškaiTiekKainuotųŠildymas1Mėn\",\n",
    "                   \"PastatoEnergijosSuvartojimoKlasė\", \"Įrengimas\", \"Šildymas\",\n",
    "                   \"PastatoEnergijosSuvartojimoKlasė\"]\n",
    "    }\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
